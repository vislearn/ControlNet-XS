model:
  base_learning_rate: 1.0e-4
  # target: sgm.models.diffusion.TwoStreamControlDiffusionEngine
  target: sgm.models.diffusion.ControlledDiffusionEngine
  params:
    scale_factor: 0.13025
    disable_first_stage_autocast: true
    denoiser_config:
      target: sgm.modules.diffusionmodules.denoiser.ControlledDiscreteDenoiser
      params:
        num_idx: 1000
        weighting_config:
          target: sgm.modules.diffusionmodules.denoiser_weighting.EpsWeighting
        scaling_config:
          target: sgm.modules.diffusionmodules.denoiser_scaling.EpsScaling
        discretization_config:
          target: sgm.modules.diffusionmodules.discretizer.LegacyDDPMDiscretization
    ckpt_path: /PATH/TO/STABLE_DIFFUSION/sd_xl_base_1.0_0.9vae.safetensors                    #  path to the StableDiffusion-XL weights
    ckpt_path_control: null
    sd_locked: true
    skip_wrapper: true
    network_config:
      target: sgm.modules.diffusionmodules.twoStreamControl.TwoStreamControlNet
      params:
        adm_in_channels: 2816
        num_classes: sequential
        use_checkpoint: true
        in_channels: 4
        out_channels: 4
        hint_channels: 3
        model_channels: 320
        attention_resolutions:
        - 4
        - 2
        num_res_blocks: 2
        channel_mult:
        - 1
        - 2
        - 4
        num_head_channels: 64
        use_spatial_transformer: true
        use_linear_in_transformer: true
        transformer_depth:
        - 1
        - 2
        - 10
        context_dim: 2048
        spatial_transformer_attn_type: softmax-xformers
        legacy: false
        infusion2control: cat
        guiding: encoder_double
        two_stream_mode: cross
        control_model_ratio: 0.05
        control_mode: midas
        learn_embedding: false
        prune_until: null
        fixed: true
    conditioner_config:
      target: sgm.modules.encoders.modules.GeneralConditioner
      params:
        emb_models:
        - is_trainable: false
          input_key: caption
          target: sgm.modules.encoders.modules.FrozenCLIPEmbedder
          params:
            layer: hidden
            layer_idx: 11
        - is_trainable: false
          input_key: caption
          target: sgm.modules.encoders.modules.FrozenOpenCLIPEmbedder2
          params:
            arch: ViT-bigG-14
            version: laion2b_s39b_b160k
            freeze: true
            layer: penultimate
            always_return_pooled: true
            legacy: false
        - is_trainable: false
          input_key: original_size_as_tuple
          target: sgm.modules.encoders.modules.ConcatTimestepEmbedderND
          params:
            outdim: 256
        - is_trainable: false
          input_key: crop_coords_top_left
          target: sgm.modules.encoders.modules.ConcatTimestepEmbedderND
          params:
            outdim: 256
        - is_trainable: false
          input_key: target_size_as_tuple
          target: sgm.modules.encoders.modules.ConcatTimestepEmbedderND
          params:
            outdim: 256
    first_stage_config:
      target: sgm.models.autoencoder.AutoencoderKLInferenceWrapper
      params:
        embed_dim: 4
        monitor: val/rec_loss
        ddconfig:
          attn_type: vanilla-xformers
          double_z: true
          z_channels: 4
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult:
          - 1
          - 2
          - 4
          - 4
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity
    loss_fn_config:
      target: sgm.modules.diffusionmodules.loss.StandardDiffusionLoss
      params:
        batch2model_keys:
        - hint
        sigma_sampler_config:
          target: sgm.modules.diffusionmodules.sigma_sampling.DiscreteSampling
          params:
            num_idx: 1000
            discretization_config:
              target: sgm.modules.diffusionmodules.discretizer.LegacyDDPMDiscretization
    sampler_config:
      target: sgm.modules.diffusionmodules.sampling.EulerEDMSampler
      params:
        num_steps: 50
        discretization_config:
          target: sgm.modules.diffusionmodules.discretizer.LegacyDDPMDiscretization
        guider_config:
          target: sgm.modules.diffusionmodules.guiders.VanillaCFG
          params:
            scale: 7.5
    input_key: image

data:
  target: main.DataModuleFromConfig
  params:
    batch_size: 1
    num_workers: 1
    wrap: false
    train:
      target: ldm.data.dummy_set.DummyBase
      params:
        data_root: /PATH/TO/TRAINING/SET
        size: 512
        np_format: False
        control_mode: image
        original_size_as_tuple: true
        crop_coords_top_left: true
        target_size_as_tuple: true
    validation:
      target: ldm.data.dummy_set.DummyBase
      params:
        data_root: /PATH/TO/VALIDATION/SET
        size: 512
        np_format: False
        control_mode: image
        original_size_as_tuple: true
        crop_coords_top_left: true
        target_size_as_tuple: true

lightning:
  modelcheckpoint:
    params:
      every_n_train_steps: 2500

  callbacks:
    metrics_over_trainsteps_checkpoint:
      params:
        every_n_train_steps: 2500

    image_logger:
      target: main.ImageLogger
      params:
        disabled: False
        enable_autocast: False
        batch_frequency: 2500
        max_images: 8
        increase_log_steps: True
        log_first_step: False
        log_images_kwargs:
          use_ema_scope: False
          N: 8
          n_rows: 2

  trainer:
    devices: 0,
    benchmark: True
    num_sanity_val_steps: 0
    accumulate_grad_batches: 1
    max_epochs: 1000
    accelerator: ddp
    gpus: 0,
    gradient_clip_val: 0.01